{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 800, 800])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "\n",
    "image = torch.zeros((1, 3, 800, 800)).float()\n",
    "bbox = torch.FloatTensor([[20, 30, 400, 500], [300, 400, 500, 600]])\n",
    "labels = torch.LongTensor([6, 8])\n",
    "sub_sample = 16\n",
    "\n",
    "dummy_img = torch.zeros((1, 3, 800, 800)).float()\n",
    "print(dummy_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = torchvision.models.vgg16(pretrained=True)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe = list(model.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "512\n"
     ]
    }
   ],
   "source": [
    "req_features = []\n",
    "k = dummy_img.clone()\n",
    "for i in fe:\n",
    "    k = i(k)\n",
    "    if k.size()[2] < 800//16:\n",
    "        break\n",
    "    req_features.append(i)\n",
    "    out_channels = k.size()[1]\n",
    "    \n",
    "print(len(req_features))\n",
    "print(out_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "faster_rcnn_fe_extractor = nn.Sequential(*req_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (3): ReLU(inplace=True)\n",
      "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (6): ReLU(inplace=True)\n",
      "  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (8): ReLU(inplace=True)\n",
      "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (11): ReLU(inplace=True)\n",
      "  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (13): ReLU(inplace=True)\n",
      "  (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (15): ReLU(inplace=True)\n",
      "  (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (18): ReLU(inplace=True)\n",
      "  (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (20): ReLU(inplace=True)\n",
      "  (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (22): ReLU(inplace=True)\n",
      "  (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (25): ReLU(inplace=True)\n",
      "  (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (27): ReLU(inplace=True)\n",
      "  (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (29): ReLU(inplace=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(faster_rcnn_fe_extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512, 50, 50])\n"
     ]
    }
   ],
   "source": [
    "out_map = faster_rcnn_fe_extractor(image)\n",
    "print(out_map.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 4)\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "ratios = [0.5, 1, 2]\n",
    "anchor_scales = [8, 16, 32]\n",
    "\n",
    "anchor_base = np.zeros((len(ratios) * len(anchor_scales), 4))\n",
    "print(anchor_base.shape)\n",
    "print(anchor_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.0 8.0\n"
     ]
    }
   ],
   "source": [
    "ctr_x = sub_sample / 2\n",
    "ctr_y = sub_sample / 2\n",
    "\n",
    "print(ctr_x, ctr_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.50966799187809 181.01933598375618\n",
      "181.01933598375618 362.03867196751236\n",
      "362.03867196751236 724.0773439350247\n",
      "128.0 128.0\n",
      "256.0 256.0\n",
      "512.0 512.0\n",
      "181.01933598375618 90.50966799187809\n",
      "362.03867196751236 181.01933598375618\n",
      "724.0773439350247 362.03867196751236\n",
      "[[ -37.254834    -82.50966799   53.254834     98.50966799]\n",
      " [ -82.50966799 -173.01933598   98.50966799  189.01933598]\n",
      " [-173.01933598 -354.03867197  189.01933598  370.03867197]\n",
      " [ -56.          -56.           72.           72.        ]\n",
      " [-120.         -120.          136.          136.        ]\n",
      " [-248.         -248.          264.          264.        ]\n",
      " [ -82.50966799  -37.254834     98.50966799   53.254834  ]\n",
      " [-173.01933598  -82.50966799  189.01933598   98.50966799]\n",
      " [-354.03867197 -173.01933598  370.03867197  189.01933598]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(ratios)):\n",
    "    for j in range(len(anchor_scales)):\n",
    "        h = sub_sample * anchor_scales[j] * np.sqrt(ratios[i])\n",
    "        w = sub_sample * anchor_scales[j] * np.sqrt(1./ratios[i])\n",
    "        \n",
    "        print(h, w)\n",
    "        \n",
    "        index = i * len(anchor_scales) + j\n",
    "        \n",
    "        anchor_base[index, 0] = ctr_y - h/2\n",
    "        anchor_base[index, 1] = ctr_x - w/2\n",
    "        anchor_base[index, 2] = ctr_y + h/2\n",
    "        anchor_base[index, 3] = ctr_x + w/2\n",
    "\n",
    "print(anchor_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "[ 16  32  48  64  80  96 112 128 144 160 176 192 208 224 240 256 272 288\n",
      " 304 320 336 352 368 384 400 416 432 448 464 480 496 512 528 544 560 576\n",
      " 592 608 624 640 656 672 688 704 720 736 752 768 784 800]\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "fe_size = 800 // 16\n",
    "print(fe_size)\n",
    "ctr_x = np.arange(16, (fe_size+1) * 16, 16)\n",
    "ctr_y = np.arange(16, (fe_size+1) * 16, 16)\n",
    "print(ctr_y)\n",
    "print(len(ctr_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctr = np.zeros((2500, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "for x in range(len(ctr_x)):\n",
    "    for y in range(len(ctr_y)):\n",
    "        ctr[index, 1] = ctr_x[x] - 8\n",
    "        ctr[index, 0] = ctr_y[y] - 8\n",
    "        index +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22500, 4)\n"
     ]
    }
   ],
   "source": [
    "anchors = np.zeros((fe_size * fe_size * 9, 4))\n",
    "index = 0\n",
    "for c in ctr:\n",
    "    ctr_y, ctr_x = c\n",
    "    for i in range(len(ratios)):\n",
    "        for j in range(len(anchor_scales)):\n",
    "            h = sub_sample * anchor_scales[j] * np.sqrt(ratios[i])\n",
    "            w = sub_sample * anchor_scales[j] * np.sqrt(1./ ratios[i])\n",
    "            anchors[index, 0] = ctr_y - h / 2.\n",
    "            anchors[index, 1] = ctr_x - w / 2.\n",
    "            anchors[index, 2] = ctr_y + h / 2.\n",
    "            anchors[index, 3] = ctr_x + w / 2.\n",
    "            index += 1\n",
    "print(anchors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8940,)\n"
     ]
    }
   ],
   "source": [
    "index_inside = np.where(\n",
    "(anchors[:, 0] >= 0) &\n",
    "(anchors[:,1] >=0) &\n",
    "(anchors[:, 2] <= 800) &\n",
    "(anchors[:, 3] <= 800))[0]\n",
    "\n",
    "print(index_inside.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8940,)\n"
     ]
    }
   ],
   "source": [
    "label = np.empty((len(index_inside), ), dtype = np.int32)\n",
    "label.fill(-1)\n",
    "print(label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8940, 4)\n"
     ]
    }
   ],
   "source": [
    "valid_anchor_boxes = anchors[index_inside]\n",
    "print(valid_anchor_boxes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ious = np.empty((len(valid_anchor_boxes), 2), dtype = np.float32)\n",
    "ious.fill(0)\n",
    "for num1, i in enumerate(valid_anchor_boxes):\n",
    "    ya1, xa1, ya2, xa2 = i\n",
    "    anchor_area = (ya2 - ya1) * (xa2 - xa1)\n",
    "    for num2, j in enumerate(bbox):\n",
    "        yb1, xb1, yb2, xb2 = j\n",
    "        box_area = (yb2 - yb1) * (xb2 - xb1)\n",
    "        \n",
    "        inter_x1 = max([xb1, xa1])\n",
    "        inter_y1 = max([yb1, ya1])\n",
    "        inter_x2 = min([xb2, xa2])\n",
    "        inter_y2 = min([yb2, ya2])\n",
    "        \n",
    "        if(inter_x1 < inter_x2) and (inter_y1 < inter_y2):\n",
    "            iter_area = (inter_y2 - inter_y1) * (inter_x2 - inter_x1)\n",
    "            iou = iter_area / (anchor_area + box_area - iter_area)\n",
    "        else:\n",
    "            iou = 0\n",
    "        \n",
    "        ious[num1, num2] = iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8940, 2)\n"
     ]
    }
   ],
   "source": [
    "print(ious.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Highest IOU of bounding box-1 and bounding box-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2262 5620]\n",
      "[0.68130493 0.61035156]\n"
     ]
    }
   ],
   "source": [
    "gt_argmax_ious = np.argmax(ious, axis = 0)\n",
    "print(gt_argmax_ious)\n",
    "\n",
    "gt_max_ious = ious[gt_argmax_ious, np.arange(ious.shape[1])]\n",
    "print(gt_max_ious)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding maximum IOU in bounding box-1, box-2 for every 8940 instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8940,)\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0.06811669 0.07083762 0.07083762 ... 0.         0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "argmax_ious = ious.argmax(axis=1)\n",
    "print(argmax_ious.shape)\n",
    "print(argmax_ious)\n",
    "\n",
    "max_ious = ious[np.arange(len(index_inside)), argmax_ious]\n",
    "print(max_ious)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([2262, 2508, 5620, 5628, 5636, 5644, 5866, 5874, 5882, 5890, 6112,\n",
      "       6120, 6128, 6136, 6358, 6366, 6374, 6382]), array([0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))\n"
     ]
    }
   ],
   "source": [
    "gt_argmax_ious = np.where(ious == gt_max_ious)\n",
    "print(gt_argmax_ious)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_iou_threshold = 0.7\n",
    "neg_iou_threshold = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8940,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_ious.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "label[max_ious < neg_iou_threshold] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in gt_argmax_ious[0]:\n",
    "    label[x] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "label[max_ious >= pos_iou_threshold] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8940,)\n"
     ]
    }
   ],
   "source": [
    "print(label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_ratio = 0.5\n",
    "n_sample = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pos = pos_ratio * n_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_index = np.where(label == 1)[0]\n",
    "if len(pos_index) > n_pos:\n",
    "    disable_index = np.random.choice(pos_index, size = (len(pos_index) - n_pos), replace = False)\n",
    "    label[disable_index] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neg = n_sample - np.sum(label == 1)\n",
    "neg_index = np.where(label == 0)[0]\n",
    "if len(neg_index) > n_neg:\n",
    "    disable_index = np.random.choice(neg_index, size = (len(neg_index) - n_neg), replace = False)\n",
    "    label[disable_index] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 20.,  30., 400., 500.],\n",
       "        [300., 400., 500., 600.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iou_bbox = bbox[argmax_ious]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 20.,  30., 400., 500.],\n",
       "        [ 20.,  30., 400., 500.],\n",
       "        [ 20.,  30., 400., 500.],\n",
       "        ...,\n",
       "        [ 20.,  30., 400., 500.],\n",
       "        [ 20.,  30., 400., 500.],\n",
       "        [ 20.,  30., 400., 500.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_iou_bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8940, 4)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_anchor_boxes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 13.49033201,  10.745166  , 194.50966799, 101.254834  ])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_anchor_boxes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = valid_anchor_boxes[:, 2] - valid_anchor_boxes[:, 0]\n",
    "width = valid_anchor_boxes[:, 3] - valid_anchor_boxes[:, 1]\n",
    "ctr_y = valid_anchor_boxes[:, 0] + 0.5 * height\n",
    "ctr_x = valid_anchor_boxes[:, 1] + 0.5 * width\n",
    "\n",
    "base_height = (max_iou_bbox[:, 2] - max_iou_bbox[:, 0]).cpu().numpy()\n",
    "base_width = (max_iou_bbox[:, 3] - max_iou_bbox[:, 1]).cpu().numpy()\n",
    "base_ctr_y = max_iou_bbox[:, 0].cpu().numpy() + 0.5 * base_height\n",
    "base_ctr_x = max_iou_bbox[:, 1].cpu().numpy() + 0.5 * base_width\n",
    "\n",
    "eps = np.finfo(height.dtype).eps\n",
    "height = np.maximum(height, eps)\n",
    "width = np.maximum(width, eps)\n",
    "\n",
    "dy = (base_ctr_y - ctr_y) / height\n",
    "dx = (base_ctr_x - ctr_x) / width\n",
    "dh = np.log(base_height / height)\n",
    "dw = np.log(base_width / width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.5855728   2.30914558  0.7415674   1.64727602]\n",
      " [ 0.49718446  2.30914558  0.7415674   1.64727602]\n",
      " [ 0.40879611  2.30914558  0.7415674   1.64727602]\n",
      " ...\n",
      " [-2.50801936 -5.29225232  0.7415674   1.64727602]\n",
      " [-2.59640771 -5.29225232  0.7415674   1.64727602]\n",
      " [-2.68479606 -5.29225232  0.7415674   1.64727602]]\n"
     ]
    }
   ],
   "source": [
    "anchor_locs = np.vstack((dy, dx, dh, dw)).transpose()\n",
    "print(anchor_locs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_labels = np.empty((len(anchors),), dtype = label.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_labels.fill(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_labels[index_inside] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_locations = np.empty((len(anchors),) + anchors.shape[1:], dtype = anchor_locs.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid_channels = 512\n",
    "in_channels = 512\n",
    "n_anchor = 9\n",
    "conv1 = nn.Conv2d(in_channels, mid_channels, 3, 1, 1)\n",
    "reg_layer = nn.Conv2d(mid_channels, n_anchor*4, 1, 1, 0)\n",
    "cls_layer = nn.Conv2d(mid_channels, n_anchor*2, 1, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1.weight.data.normal_(0, 0.01)\n",
    "conv1.bias.data.zero_()\n",
    "\n",
    "reg_layer.weight.data.normal_(0, 0.01)\n",
    "reg_layer.bias.data.zero_()\n",
    "\n",
    "cls_layer.weight.data.normal_(0, 0.01)\n",
    "cls_layer.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512, 50, 50])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_map.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = conv1(out_map)\n",
    "pred_anchor_locs = reg_layer(x)\n",
    "pred_cls_scores = cls_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 18, 50, 50]) torch.Size([1, 36, 50, 50])\n"
     ]
    }
   ],
   "source": [
    "print(pred_cls_scores.shape, pred_anchor_locs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 22500, 4])\n"
     ]
    }
   ],
   "source": [
    "pred_anchor_locs = pred_anchor_locs.permute(0, 2, 3, 1).contiguous().view(1, -1, 4)\n",
    "print(pred_anchor_locs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 50, 50, 18])\n"
     ]
    }
   ],
   "source": [
    "pred_cls_scores = pred_cls_scores.permute(0, 2, 3, 1).contiguous()\n",
    "print(pred_cls_scores.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 22500])\n"
     ]
    }
   ],
   "source": [
    "objectness_score = pred_cls_scores.view(1, 50, 50, 9, 2)[:, :, :, :, 1].contiguous().view(1, -1)\n",
    "print(objectness_score.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 22500, 2])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_cls_scores = pred_cls_scores.view(1, -1, 2)\n",
    "pred_cls_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "nms_thresh = 0.7\n",
    "n_train_pre_nms = 12000\n",
    "n_train_post_nms = 2000\n",
    "n_test_pre_nms = 6000\n",
    "n_test_post_nms = 300\n",
    "min_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22500, 4)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "anc_height = anchors[:, 2] - anchors[:, 0]\n",
    "anc_width = anchors[:, 3] - anchors[:, 1]\n",
    "anc_ctr_y = anchors[:, 0] + 0.5 * anc_height\n",
    "anc_ctr_x = anchors[:, 1] + 0.5 * anc_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([22500, 4])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_anchor_locs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_anchor_locs_numpy = pred_anchor_locs[0].data.numpy()\n",
    "objectness_score_numpy = objectness_score[0].data.numpy()\n",
    "dy = pred_anchor_locs_numpy[:, 0::4]\n",
    "dx = pred_anchor_locs_numpy[:, 1::4]\n",
    "dh = pred_anchor_locs_numpy[:, 2::4]\n",
    "dw = pred_anchor_locs_numpy[:, 3::4]\n",
    "ctr_y = dy * anc_height[:, np.newaxis] + anc_ctr_y[:, np.newaxis]\n",
    "ctr_x = dx * anc_width[:, np.newaxis] + anc_ctr_x[:, np.newaxis]\n",
    "h = np.exp(dh) * anc_height[:, np.newaxis]\n",
    "w = np.exp(dw) * anc_width[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi = np.zeros(pred_anchor_locs_numpy.shape, dtype=anchor_locs.dtype)\n",
    "roi[:, 0::4] = ctr_y - 0.5 * h\n",
    "roi[:, 1::4] = ctr_x - 0.5 * w\n",
    "roi[:, 2::4] = ctr_y + 0.5 * h\n",
    "roi[:, 3::4] = ctr_x + 0.5 * w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.           0.          55.55356459  97.95980537]\n",
      " [  0.           0.          93.62134298 201.07869439]\n",
      " [  0.           0.         191.03594569 361.40322306]\n",
      " ...\n",
      " [701.84662553 749.25349388 800.         800.        ]\n",
      " [616.12116492 704.74719399 800.         800.        ]\n",
      " [415.84887997 611.21031646 800.         800.        ]]\n"
     ]
    }
   ],
   "source": [
    "img_size = (800, 800) #Image size\n",
    "roi[:, slice(0, 4, 2)] = np.clip(\n",
    "            roi[:, slice(0, 4, 2)], 0, img_size[0])\n",
    "roi[:, slice(1, 4, 2)] = np.clip(\n",
    "    roi[:, slice(1, 4, 2)], 0, img_size[1])\n",
    "print(roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22500,)\n",
      "(22500, 4)\n",
      "[461 447 875 ... 446 455  17]\n",
      "(12000, 4)\n",
      "[[  0.           0.         206.33910605 411.37331389]\n",
      " [693.80619277   0.         800.          55.66087923]\n",
      " [584.40189007   0.         800.         394.748768  ]\n",
      " ...\n",
      " [  0.         417.29678278 579.72181682 784.85981279]\n",
      " [149.47247598 401.29678278 800.         768.85981279]\n",
      " [133.47247598 401.29678278 800.         768.85981279]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# %% remove small ones\n",
    "hs = roi[:, 2] - roi[:, 0]\n",
    "ws = roi[:, 3] - roi[:, 1]\n",
    "keep = np.where((hs >= min_size) & (ws >= min_size))[0]\n",
    "roi = roi[keep, :]\n",
    "scores = objectness_score_numpy[keep]\n",
    "print(scores.shape)\n",
    "print(roi.shape)\n",
    "\n",
    "# %% sort and pick\n",
    "ordered_scores = scores.ravel().argsort()[::-1]\n",
    "print(ordered_scores)\n",
    "ordered_scores = ordered_scores[:n_train_pre_nms]\n",
    "roi = roi[ordered_scores, :]\n",
    "print(roi.shape)\n",
    "print(roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = roi[:, 0]\n",
    "x1 = roi[:, 1]\n",
    "y2 = roi[:, 2]\n",
    "x2 = roi[:, 3]\n",
    "\n",
    "areas = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "\n",
    "order = ordered_scores.argsort()[::-1]\n",
    "keep = []\n",
    "\n",
    "while order.size > 0:\n",
    "    i = order[0]\n",
    "    keep.append(i)\n",
    "    xx1 = np.maximum(x1[i], x1[order[1:]])\n",
    "    yy1 = np.maximum(y1[i], y1[order[1:]])\n",
    "    xx2 = np.minimum(x2[i], x2[order[1:]])\n",
    "    yy2 = np.minimum(y2[i], y2[order[1:]])\n",
    "    w = np.maximum(0.0, xx2 - xx1 + 1)\n",
    "    h = np.maximum(0.0, yy2 - yy1 + 1)\n",
    "    inter = w * h\n",
    "    ovr = inter / (areas[i] + areas[order[1:]] - inter)\n",
    "    inds = np.where(ovr <= nms_thresh)[0]\n",
    "    order = order[inds + 1]\n",
    "    \n",
    "keep = keep[:n_train_post_nms]  # while training/testing , use accordingly\n",
    "roi = roi[keep]  # the final region proposals for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1482, 4)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 128\n",
    "pos_ratio = 0.25\n",
    "pos_iou_thresh = 0.5\n",
    "neg_iou_thresh_hi = 0.5\n",
    "neg_iou_thresh_lo = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1482, 2)\n"
     ]
    }
   ],
   "source": [
    "ious = np.empty((len(roi), 2), dtype = np.float32)\n",
    "ious.fill(0)\n",
    "\n",
    "for num1, i in enumerate(roi):\n",
    "    ya1, xa1, ya2, xa2 = i\n",
    "    anchor_area = (ya2 - ya1) * (xa2 - xa1)\n",
    "    for num1, j in enumerate(bbox):\n",
    "        yb1, xb1, yb2, xb2 = j\n",
    "        bbox_area = (yb2 - yb1) * (xb2 - xb1)\n",
    "        \n",
    "        inter_x1 = max([xb1, xa1])\n",
    "        inter_y1 = max([yb1, ya1])\n",
    "        inter_x2 = min([xb2, xa2])\n",
    "        inter_y2 = min([yb2, ya2])\n",
    "        \n",
    "        if (inter_x1 < inter_x2) and (inter_y1 < inter_y2):\n",
    "            iter_area = (inter_y2 - inter_y1) * (inter_x2 - inter_x1)\n",
    "            iou = iter_area / (anchor_area + box_area - iter_area)            \n",
    "        else:\n",
    "            iou = 0\n",
    "            \n",
    "        ious[num1, num2] = iou\n",
    "print(ious.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 ... 0 0 0]\n",
      "[1.0825591 0.        0.        ... 0.        0.        0.       ]\n",
      "tensor([8, 6, 6,  ..., 6, 6, 6])\n"
     ]
    }
   ],
   "source": [
    "gt_assignment = ious.argmax(axis=1)\n",
    "max_ious = ious.max(axis=1)\n",
    "print(gt_assignment)\n",
    "print(max_ious)\n",
    "\n",
    "gt_roi_label = labels[gt_assignment]\n",
    "print(gt_roi_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "pos_roi_per_image = int(n_samples * pos_ratio)\n",
    "pos_index = np.where(max_ious >= pos_iou_thresh)[0]\n",
    "pos_roi_per_this_image = int(min(pos_roi_per_image, pos_index.size))\n",
    "if pos_index.size > 0:\n",
    "    pos_index = np.random.choice(\n",
    "        pos_index, size=pos_roi_per_this_image, replace=False)\n",
    "print(pos_roi_per_this_image)\n",
    "print(pos_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124\n",
      "[1083 1185  612  534 1045  794 1330  497   47  477  647  440  594 1274\n",
      "  217 1354 1215  370  369 1338 1047 1363 1289  673 1062  768 1360  220\n",
      "   79  840 1426  660 1411 1032  335  764  767 1380  178  416  831  568\n",
      "  303  909 1057  324  244  971  684 1407  637  331  412  575 1447  674\n",
      " 1395  921   99  266  325 1154   67 1080  959 1142  283  339  661  531\n",
      "   17  528  775   34  640  163 1009  734  676  233  843  525  762  122\n",
      "  782 1073 1242 1222 1042  250 1287  961  472  393  986 1359  666  541\n",
      "  655  626  352  357  238  104  502 1068   27 1349  374  879  474 1480\n",
      "   18  216  641  995  857 1283 1146  707 1390  675 1223  842]\n"
     ]
    }
   ],
   "source": [
    "neg_index = np.where((max_ious < neg_iou_thresh_hi) &\n",
    "                     (max_ious >= neg_iou_thresh_lo))[0]\n",
    "neg_roi_per_this_image = n_sample - pos_roi_per_this_image\n",
    "neg_roi_per_this_image = int(min(neg_roi_per_this_image,\n",
    "                                 neg_index.size))\n",
    "if neg_index.size > 0:\n",
    "    neg_index = np.random.choice(\n",
    "        neg_index, size=neg_roi_per_this_image, replace=False)\n",
    "print(neg_roi_per_this_image)\n",
    "print(neg_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125, 4)\n"
     ]
    }
   ],
   "source": [
    "keep_index = np.append(pos_index, neg_index)\n",
    "gt_roi_labels = gt_roi_label[keep_index]\n",
    "gt_roi_labels[pos_roi_per_this_image:] = 0  # negative labels --> 0\n",
    "sample_roi = roi[keep_index]\n",
    "print(sample_roi.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox_for_sampled_roi = bbox[gt_assignment[keep_index]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([125, 4])\n"
     ]
    }
   ],
   "source": [
    "print(bbox_for_sampled_roi.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = sample_roi[:, 2] - sample_roi[:, 0]\n",
    "width = sample_roi[:, 3] - sample_roi[:, 1]\n",
    "ctr_y = sample_roi[:, 0] + 0.5 * height\n",
    "ctr_x = sample_roi[:, 1] + 0.5 * width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125, 4)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_roi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_height = bbox_for_sampled_roi[:, 2] - bbox_for_sampled_roi[:, 0]\n",
    "base_width = bbox_for_sampled_roi[:, 3] - bbox_for_sampled_roi[:, 1]\n",
    "base_ctr_y = (bbox_for_sampled_roi[:, 0] + 0.5 * base_height).cpu().numpy()\n",
    "base_ctr_x = (bbox_for_sampled_roi[:, 1] + 0.5 * base_width).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125, 4)\n"
     ]
    }
   ],
   "source": [
    "eps = np.finfo(height.dtype).eps\n",
    "height = np.maximum(height, eps)\n",
    "width = np.maximum(width, eps)\n",
    "dy = (base_ctr_y - ctr_y) / height\n",
    "dx = (base_ctr_x - ctr_x) / width\n",
    "dh = np.log(base_height.cpu().numpy() / height)\n",
    "dw = np.log(base_width.cpu().numpy() / width)\n",
    "gt_roi_locs = np.vstack((dy, dx, dh, dw)).transpose()\n",
    "print(gt_roi_locs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125, 4)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_roi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "rois = torch.from_numpy(sample_roi).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([125, 4])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rois.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_indices = np.zeros((len(rois), ), dtype = np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roi_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_indices = torch.from_numpy(roi_indices).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([125]) torch.Size([125, 4])\n"
     ]
    }
   ],
   "source": [
    "print(roi_indices.shape, rois.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([125, 5])\n"
     ]
    }
   ],
   "source": [
    "indices_and_roi = torch.cat([roi_indices[:, None], rois], dim = 1)\n",
    "print(indices_and_roi.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([125, 5])\n"
     ]
    }
   ],
   "source": [
    "xy_indices_and_rois = indices_and_roi[:, [0, 2, 1, 4, 3]]\n",
    "indices_and_roi = xy_indices_and_rois.contiguous()\n",
    "print(xy_indices_and_rois.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0.0000, 154.5457, 109.9299, 245.1085, 290.5577])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xy_indices_and_rois[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 7  # max pool 7x7\n",
    "adaptive_max_pool = nn.AdaptiveMaxPool2d(size)\n",
    "output = []\n",
    "rois = indices_and_roi.data.float()\n",
    "rois[:, 1:].mul_(1 / 16.0)  # Subsampling ratio skipping the index\n",
    "rois = rois.long()\n",
    "num_rois = rois.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_rois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = []\n",
    "for roi in rois:\n",
    "    roi_feature = out_map[..., roi[0]:roi[2]+1, roi[1]:roi[3]+1]\n",
    "    output.append(adaptive_max_pool(roi_feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([125, 512, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "output = torch.cat(output, 0)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = output.view(output.size(0), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([125, 25088])"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_head_classifier = nn.Sequential(*[nn.Linear(25088, 4096), nn.Linear(4096, 4096)])\n",
    "cls_loc = nn.Linear(4096, 21*4)\n",
    "\n",
    "cls_loc.weight.data.normal_(0, 0.01)\n",
    "cls_loc.bias.data.zero_()\n",
    "\n",
    "score = nn.Linear(4096, 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([125, 25088])"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = roi_head_classifier(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_cls_loc = cls_loc(k)\n",
    "roi_cls_score = score(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([125, 84]) torch.Size([125, 21])\n"
     ]
    }
   ],
   "source": [
    "print(roi_cls_loc.shape, roi_cls_score.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 22500, 4])\n",
      "torch.Size([1, 22500, 2])\n",
      "(22500, 4)\n",
      "(22500,)\n"
     ]
    }
   ],
   "source": [
    "print(pred_anchor_locs.shape)\n",
    "print(pred_cls_scores.shape)\n",
    "print(anchor_locations.shape)\n",
    "print(anchor_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([22500, 4]) torch.Size([22500, 2]) torch.Size([22500, 4]) torch.Size([22500])\n"
     ]
    }
   ],
   "source": [
    "rpn_loc = pred_anchor_locs[0]\n",
    "rpn_score = pred_cls_scores[0]\n",
    "\n",
    "gt_rpn_loc = torch.from_numpy(anchor_locations)\n",
    "gt_rpn_score = torch.from_numpy(anchor_labels)\n",
    "\n",
    "print(rpn_loc.shape, rpn_score.shape, gt_rpn_loc.shape, gt_rpn_score.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "rpn_cls_loss = F.cross_entropy(rpn_score, gt_rpn_score.long(), ignore_index=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6914, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(rpn_cls_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = gt_rpn_score > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([22500])"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([22500, 4])\n"
     ]
    }
   ],
   "source": [
    "mask = pos.unsqueeze(1).expand_as(rpn_loc)\n",
    "print(mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 4]) torch.Size([18, 4])\n"
     ]
    }
   ],
   "source": [
    "mask_loc_preds = rpn_loc[mask].view(-1, 4)\n",
    "mask_loc_targets = gt_rpn_loc[mask].view(-1, 4)\n",
    "print(mask_loc_preds.shape, mask_loc_preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_loc_preds = mask_loc_preds.float()\n",
    "mask_loc_targets = mask_loc_targets.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.abs(mask_loc_targets - mask_loc_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0004, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "rpn_loc_loss = ((x < 1).float() * 0.5 * x**2) + ((x >= 1).float() * (x-0.5))\n",
    "print(rpn_loc_loss.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpn_lambda = 10\n",
    "N_reg = (gt_rpn_score > 0).float().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpn_loc_loss = rpn_loc_loss.sum() / N_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.9661e-05, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rpn_loc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6916, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "rpn_loss = rpn_cls_loss + (rpn_lambda * rpn_loc_loss)\n",
    "print(rpn_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([125, 84])\n",
      "torch.Size([125, 21])\n"
     ]
    }
   ],
   "source": [
    "print(roi_cls_loc.shape)\n",
    "print(roi_cls_score.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125, 4)\n",
      "torch.Size([125])\n"
     ]
    }
   ],
   "source": [
    "print(gt_roi_locs.shape)\n",
    "print(gt_roi_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([125, 4]) torch.Size([125])\n"
     ]
    }
   ],
   "source": [
    "gt_roi_loc = torch.from_numpy(gt_roi_locs)\n",
    "gt_roi_label = torch.from_numpy(np.float32(gt_roi_labels)).long()\n",
    "print(gt_roi_loc.shape, gt_roi_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.0490, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "roi_cls_loss = F.cross_entropy(roi_cls_score, gt_roi_label, ignore_index=-1)\n",
    "print(roi_cls_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([125, 21, 4])\n"
     ]
    }
   ],
   "source": [
    "n_sample = roi_cls_loc.shape[0]\n",
    "roi_loc = roi_cls_loc.view(n_sample, -1, 4)\n",
    "print(roi_loc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125\n"
     ]
    }
   ],
   "source": [
    "print(n_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([125, 4])\n"
     ]
    }
   ],
   "source": [
    "roi_loc = roi_loc[torch.arange(0, n_sample).long(), gt_roi_label]\n",
    "print(roi_loc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_roi_loc = gt_roi_loc.float()\n",
    "roi_loc = roi_loc.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(437.5732, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x_roi = torch.abs(gt_roi_loc - roi_loc)\n",
    "roi_loc_loss = ((x_roi < 1).float() * 0.5 * x_roi ** 2) + ((x_roi >= 1).float() * (x_roi - 0.5))\n",
    "print(roi_loc_loss.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(246.1453, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "roi_lambda = 10.\n",
    "N_reg_roi = (gt_rpn_score > 0).float().sum()\n",
    "roi_loc_loss = roi_loc_loss.sum() / N_reg_roi\n",
    "roi_loss = roi_cls_loss + (roi_lambda * roi_loc_loss)\n",
    "print(roi_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(246.8369, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "total_loss = rpn_loss + roi_loss\n",
    "print(total_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
